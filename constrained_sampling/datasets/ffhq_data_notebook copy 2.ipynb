{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5512a1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/anaconda3/envs/stable-dif/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f073b11-3cc5-4f4e-983e-79023e2512d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/anaconda3/envs/stable-dif/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# make sure you're logged in with \\`huggingface-cli login\\`\n",
    "# import torch\n",
    "# import argparse\n",
    "# import os\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import numpy as np\n",
    "# from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "# import os\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import torchvision.transforms as transforms \n",
    "from torchvision.datasets import VisionDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Callable, Optional\n",
    "# import glob\n",
    "import torch.nn as nn\n",
    "\n",
    "from datasets import build_loader\n",
    "\n",
    "import lpips\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import lpips\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2534da01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/anaconda3/envs/stable-dif/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/nicolas/anaconda3/envs/stable-dif/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/nicolas/anaconda3/envs/stable-dif/lib/python3.12/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    }
   ],
   "source": [
    "# Load config file\n",
    "# with initialize(version_base=None, config_path=\"../_configs\"):\n",
    "#     cfg = compose(config_name='ddrmpp.yaml')\n",
    "\n",
    "# # Define upsample operation\n",
    "upsample = nn.Upsample(scale_factor=2, mode='nearest') \n",
    "\n",
    "# # Build loader\n",
    "# loader = build_loader(cfg)\n",
    "lpips_ = lpips.LPIPS(net='alex').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c3d794",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# get image from loader\u001b[39;00m\n\u001b[1;32m      2\u001b[0m stop_at \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m it, (x, y, info) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mloader\u001b[49m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m it \u001b[38;5;241m>\u001b[39m stop_at:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loader' is not defined"
     ]
    }
   ],
   "source": [
    "# get image from loader\n",
    "stop_at = 100\n",
    "for it, (x, y, info) in enumerate(loader):\n",
    "    if it > stop_at:\n",
    "        break\n",
    "    print(info['index'][0])\n",
    "    # save_image(x[0], f'/home/nzilberstein/Inverse/_exp/input/FFHQ/{info['index'][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ac7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_upsample = upsample(x[0].unsqueeze(0)).squeeze()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(x_upsample.permute(1,2,0).detach().numpy())\n",
    "print(x_upsample.shape)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(x[0].permute(1,2,0).detach().numpy())\n",
    "\n",
    "save_image(x_upsample, 'test.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4104cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id_single = '00000'\n",
    "img_path=f'/home/nzilberstein/Inverse/PSLD/diffusion-posterior-sampling/outputs/inpainting/recon/{img_id_single}.png'\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "# img_path_reddif = f'/home/nzilberstein/diffusion-posterior-sampling/outputs/inpainting/recon/00000.png'\n",
    "# img_reddif = Image.open(img_path_reddif).convert('RGB')\n",
    "\n",
    "img_true_path = f'/home/nzilberstein/Inverse/_exp/input/FFHQ/{img_id_single}.png'\n",
    "img_true = Image.open(img_true_path).convert('RGB')\n",
    "\n",
    "# img_deg = Image.open('/home/nzilberstein/Inverse/_exp/output_inv/x_deg.png').convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1af21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_torch_psld = transforms.ToTensor()(img)\n",
    "# img_torch_reddif = transforms.ToTensor()(img_reddif)\n",
    "img_true_torch = transforms.ToTensor()(img_true)\n",
    "# img_torch_deg = transforms.ToTensor()(img_deg)\n",
    "# img_true_torch = upsample(img_true_torch.unsqueeze(0)).squeeze()\n",
    "\n",
    "mse = torch.mean((img_torch_psld - img_true_torch) ** 2, dim=(0, 1, 2))\n",
    "psnr = 10 * torch.log10(1 / (mse + 1e-10))\n",
    "print(psnr)\n",
    "\n",
    "# mse = torch.mean((img_torch_reddif - img_true_torch) ** 2, dim=(0, 1, 2))\n",
    "# psnr = 10 * torch.log10(1 / (mse + 1e-10))\n",
    "# print(psnr)\n",
    "# lpips_(img_torch_psld.cuda(), img_true_torch.cuda()), lpips_(img_torch_reddif.cuda(), img_true_torch.cuda())\n",
    "lpips_(img_torch_psld.cuda(), img_true_torch.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8772ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = make_grid([img_torch_psld, img_torch_reddif, img_true_torch, img_torch_deg], nrow=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c3fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define figure with size\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(grid.permute(1,2,0).detach().numpy())\n",
    "\n",
    "\n",
    "\n",
    "save_image(grid, 'results_inp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745291bb",
   "metadata": {},
   "source": [
    "## PSLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/nzilberstein/Inverse/_exp/output_bip/PSLD/samples'\n",
    "# img_path_input = '/home/nzilberstein/Inverse/_exp/input/FFHQ'\n",
    "# img_path = '/home/nzilberstein/Inverse/_exp/output_sr8/PSLD/samples'\n",
    "import os\n",
    "\n",
    "dino = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
    "dino = dino.eval()\n",
    "\n",
    "# Calculate FID score\n",
    "cnt = 0\n",
    "mean_psnr = 0\n",
    "mean_lpips = 0\n",
    "for item in os.listdir(img_path):\n",
    "    print(item)\n",
    "    # Check if the item is a directory (folder)\n",
    "    img_true_path = os.path.join('/home/nzilberstein/Inverse/_exp/input/FFHQ', item + '.png')\n",
    "    img_true = Image.open(img_true_path).convert('RGB')\n",
    "    img_true_torch = transforms.ToTensor()(img_true)\n",
    "    img_true_torch = upsample(img_true_torch.unsqueeze(0)).squeeze()\n",
    "    img_psld_torch_list = []\n",
    "    for img_id in os.listdir(os.path.join(img_path, item)):\n",
    "        # print(img_id)\n",
    "        if len(img_id.split('_')) == 1:\n",
    "            # print(img_id)\n",
    "            img_id_path = os.path.join(img_path, item, img_id)\n",
    "            img = Image.open(img_id_path).convert('RGB')\n",
    "\n",
    "            img_psld_torch = transforms.ToTensor()(img)\n",
    "            img_psld_torch_list.append(img_psld_torch)\n",
    "            # Transform to tensor the list\n",
    "    img_psld_torch_list = torch.stack(img_psld_torch_list)\n",
    "    # print(img_psld_torch_list.shape)\n",
    "    # Compute similarity\n",
    "    total_pair_wise_sim = 0.\n",
    "    xo_list = dino(img_psld_torch_list)\n",
    "    # del dino\n",
    "    xo_list /= xo_list.norm(dim=-1, keepdim=True)\n",
    "    # calculate the cosine similarity\n",
    "    sim = (xo_list @ xo_list.T)\n",
    "    # set the diagonal to be 0\n",
    "    sim = sim - torch.diag(sim.diag())\n",
    "    total_pair_wise_sim += sim.sum() / (sim.shape[0] * (sim.shape[0] - 1))\n",
    "    torch.clear_autocast_cache()\n",
    "        # print(total_pair_wise_sim)\n",
    "                            \n",
    "print(total_pair_wise_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb58ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00003\n",
      "temp_00002.png\n",
      "tensor(28.9770)\n",
      "tensor([[[[0.3215]]]], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "img_path = '/home/nicolas/server_nvidia/PSLD/stable-diffusion/outputs/psld-samples-mb/samples'\n",
    "# img_path = '/home/nzilberstein/Inverse/PSLD/stable-diffusion/outputs/psld-samples-bip/samples'\n",
    "img_id_max = '00003'\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Calculate FID score\n",
    "cnt = 0\n",
    "mean_psnr = 0\n",
    "mean_lpips = 0\n",
    "for item in os.listdir(img_path):\n",
    "    if item == img_id_max:\n",
    "        print(item)\n",
    "        # Check if the item is a directory (folder)\n",
    "        img_true_path = os.path.join('/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/_exp/input/FFHQ_512', item + '.png')\n",
    "        img_true = Image.open(img_true_path).convert('RGB')\n",
    "        img_true_torch = transforms.ToTensor()(img_true)\n",
    "        # img_true_torch = upsample(img_true_torch.unsqueeze(0)).squeeze()\n",
    "        for img_id in os.listdir(os.path.join(img_path, item)):\n",
    "            # print(img_id.split('.')[0].split('_'))\n",
    "            if len(img_id.split('.')[0].split('_')) == 2:\n",
    "                print(img_id)\n",
    "                img_id_path = os.path.join(img_path, item, img_id)\n",
    "                img = Image.open(img_id_path).convert('RGB')\n",
    "\n",
    "                img_psld_torch = transforms.ToTensor()(img)\n",
    "\n",
    "                mse = torch.mean((img_psld_torch - img_true_torch) ** 2, dim=(0, 1, 2))\n",
    "                psnr = 10 * torch.log10(1 / (mse + 1e-10))\n",
    "                mean_psnr = mean_psnr + psnr\n",
    "\n",
    "                lpips_val = lpips_(img_psld_torch.cuda(), img_true_torch.cuda())\n",
    "                # print(lpips_val)\n",
    "                mean_lpips = mean_lpips + lpips_val\n",
    "\n",
    "                cnt = cnt + 1\n",
    "            \n",
    "\n",
    "print(mean_psnr/cnt)\n",
    "print(mean_lpips/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4e4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "'00001' < '00006'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d5b6d6",
   "metadata": {},
   "source": [
    "## REDDIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce04119",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/_exp/_exp/output'\n",
    "img_path_input = '/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/_exp/input/FFHQ'\n",
    "coeff = 0.0\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "dino = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
    "dino = dino.eval()\n",
    "# Calculate diversity\n",
    "cnt = 0\n",
    "mean_psnr = 0\n",
    "mean_lpips = 0\n",
    "for item in os.listdir(img_path_input):\n",
    "    if item.split('.')[0] < '00040':\n",
    "        # Check if the item is a directory (folder)\n",
    "        img_psld_torch_list = []    \n",
    "        for img_id in os.listdir(os.path.join(img_path, item.split('.')[0], f'{coeff}')):\n",
    "            if (img_id.split('_')[2]).split('.')[0] != 'grid':\n",
    "                img_id_path = os.path.join(img_path, item.split('.')[0], f'{coeff}', img_id)\n",
    "                img = Image.open(img_id_path).convert('RGB')\n",
    "\n",
    "                img_psld_torch = transforms.ToTensor()(img)\n",
    "                img_psld_torch_list.append(img_psld_torch)\n",
    "                # Transform to tensor the list\n",
    "        img_psld_torch_list = torch.stack(img_psld_torch_list)\n",
    "        # print(img_psld_torch_list.shape)\n",
    "        # Compute similarity\n",
    "        total_pair_wise_sim = 0.\n",
    "        xo_list = dino(img_psld_torch_list)\n",
    "        # del dino\n",
    "        xo_list /= xo_list.norm(dim=-1, keepdim=True)\n",
    "        # calculate the cosine similarity\n",
    "        sim = (xo_list @ xo_list.T)\n",
    "        # set the diagonal to be 0\n",
    "        sim = sim - torch.diag(sim.diag())\n",
    "        total_pair_wise_sim += sim.sum() / (sim.shape[0] * (sim.shape[0] - 1))\n",
    "        torch.clear_autocast_cache()\n",
    "        # print(total_pair_wise_sim)\n",
    "                            \n",
    "print(total_pair_wise_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/nzilberstein/repository/constrained_sampling/_exp/output/rsd_stable/inp'\n",
    "img_path_input = '/home/nzilberstein/repository/constrained_sampling/_exp/input/FFHQ'\n",
    "coeff = 0.0\n",
    "import os\n",
    "import lpips\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Calculate FID score\n",
    "cnt = 0\n",
    "mean_psnr = 0\n",
    "mean_lpips = 0\n",
    "for item in os.listdir(img_path_input):\n",
    "    if item.split('.')[0] < '00004':\n",
    "        print(item)\n",
    "        # Check if the item is a directory (folder)\n",
    "        img_true_path = os.path.join(img_path_input, item)\n",
    "        # print(item)\n",
    "        img_true = Image.open(img_true_path).convert('RGB')\n",
    "        img_true_torch = transforms.ToTensor()(img_true)\n",
    "        img_true_torch = upsample(img_true_torch.unsqueeze(0)).squeeze()\n",
    "        for img_id in os.listdir(os.path.join(img_path, item.split('.')[0], '0')):\n",
    "            if img_id.split('_')[2] == \"grid.png\":\n",
    "                continue\n",
    "            img_id_path = os.path.join(img_path, item.split('.')[0], '0', img_id)\n",
    "            img = Image.open(img_id_path).convert('RGB')\n",
    "\n",
    "            img_psld_torch = transforms.ToTensor()(img)\n",
    "\n",
    "            mse = torch.mean((img_psld_torch - img_true_torch) ** 2, dim=(0, 1, 2))\n",
    "            psnr = 10 * torch.log10(1 / (mse + 1e-10))\n",
    "            mean_psnr = mean_psnr + psnr\n",
    "\n",
    "            lpips_val = lpips_(img_psld_torch.cuda(), img_true_torch.cuda())\n",
    "            mean_lpips = mean_lpips + lpips_val\n",
    "\n",
    "            cnt = cnt + 1\n",
    "            \n",
    "\n",
    "\n",
    "print(mean_psnr/cnt)\n",
    "print(mean_lpips/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/nzilberstein/Inverse/_exp/output_bip_small_nonaugm/RED_diff_nonaug'\n",
    "it = 0\n",
    "for item in os.listdir(img_path_input):\n",
    "    # Check if the item is a directory (folder)\n",
    "    if item.isnumeric():\n",
    "        print(item)\n",
    "        list_imgs = os.listdir(os.path.join(img_path_input, item))\n",
    "        idx_img = np.random.choice(len(os.listdir(os.path.join(img_path_input, item))))\n",
    "        img_true = Image.open(os.path.join(args.dir_path, item, list_imgs[idx_img])).convert('RGB')\n",
    "\n",
    "        img_torch = transforms.ToTensor()(img_true)\n",
    "\n",
    "        # Create folder if does not exist\n",
    "        if not os.path.exists(dest_folder):\n",
    "            os.makedirs(dest_folder)\n",
    "\n",
    "        save_image(img_torch, f'{dest_folder}/{it}.png')\n",
    "    it = it + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/nicolas/red_diff_stable/PSLD/stable-diffusion/outputs/psld-samples-bip/samples/00002.png\n",
    "from PIL import Image\n",
    "import lpips\n",
    "# img_path = '/home/nzilberstein/Inverse/_exp/output_rip/PSLD/samples/00003/00000.png'\n",
    "img_id_single = '00010'\n",
    "img_path = f'/home/nzilberstein/Inverse/PSLD/stable-diffusion/outputs/psld-samples-bip/samples/{img_id_single}/00000.png'\n",
    "# img_path = f'/home/nzilberstein/Inverse/_exp/output_rip/PSLD/samples_500_iter/{img_id_single}/00000.png'\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "img_path_reddif = f'/home/nzilberstein/Inverse/_exp/output_rip/RED_diff/10.0/x_hat_1.png'\n",
    "# img_path_reddif = f'/home/nzilberstein/Inverse/_exp/output_rip/RED_diff/{img_id_single}/0.0/x_hat_1.png'\n",
    "img_reddif = Image.open(img_path_reddif).convert('RGB')\n",
    "\n",
    "img_true_path = f'/home/nzilberstein/Inverse/_exp/input/FFHQ/{img_id_single}.png'\n",
    "# img_true_path = '/home/nzilberstein/PSLD/diffusion-posterior-sampling/data/samples/00003.png'\n",
    "img_true = Image.open(img_true_path).convert('RGB')\n",
    "\n",
    "img_deg = Image.open('/home/nzilberstein/Inverse/_exp/output_inv/x_deg.png').convert('RGB')\n",
    "# Define upsample operation\n",
    "upsample = nn.Upsample(scale_factor=2, mode='nearest') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
