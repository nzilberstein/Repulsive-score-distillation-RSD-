{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5512a1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nzilberstein/repository/constrained_sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nzilberstein/anaconda3/envs/stable-dif/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f073b11-3cc5-4f4e-983e-79023e2512d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nzilberstein/anaconda3/envs/stable-dif/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# make sure you're logged in with \\`huggingface-cli login\\`\n",
    "# import torch\n",
    "# import argparse\n",
    "# import os\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import numpy as np\n",
    "# from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "# import os\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import torchvision.transforms as transforms \n",
    "from torchvision.datasets import VisionDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Callable, Optional\n",
    "# import glob\n",
    "import torch.nn as nn\n",
    "\n",
    "from datasets import build_loader\n",
    "\n",
    "\n",
    "import lpips\n",
    "import torch\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2534da01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nzilberstein/anaconda3/envs/stable-dif/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/nzilberstein/anaconda3/envs/stable-dif/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/nzilberstein/anaconda3/envs/stable-dif/lib/python3.12/site-packages/lpips/weights/v0.1/alex.pth\n"
     ]
    }
   ],
   "source": [
    "# Load config file\n",
    "# with initialize(version_base=None, config_path=\"../_configs\"):\n",
    "#     cfg = compose(config_name='ddrmpp.yaml')\n",
    "\n",
    "# # Define upsample operation\n",
    "upsample = nn.Upsample(scale_factor=2, mode='nearest') \n",
    "# downsample = nn.AvgPool2d(2, 2)\n",
    "# downsample = F.interpolate(scale_factor=0.5, mode='nearest')\n",
    "\n",
    "# # Build loader\n",
    "# loader = build_loader(cfg)\n",
    "lpips_ = lpips.LPIPS(net='alex').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89e4fdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/nzilberstein/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 512, 512] at entry 0 and [3, 516, 2058] at entry 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m     img_psld_torch_list\u001b[38;5;241m.\u001b[39mappend(img_psld_torch)\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;66;03m# Transform to tensor the list\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m img_psld_torch_list \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_psld_torch_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# print(img_psld_torch_list.shape)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Compute similarity\u001b[39;00m\n\u001b[1;32m     36\u001b[0m total_pair_wise_sim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 512, 512] at entry 0 and [3, 516, 2058] at entry 7"
     ]
    }
   ],
   "source": [
    "# algo = 'reddiff'\n",
    "# algo = 'rsd_stable'\n",
    "algo = 'rsd_stable_repulsion_gamma80'\n",
    "max_img_id = '00018'\n",
    "\n",
    "# img_path = f'/home/nzilberstein/repository/constrained_sampling/_exp/output/{algo}'\n",
    "img_path = f'/home/nzilberstein/repository/constrained_sampling/_exp/output/{algo}/inp_large_box'\n",
    "img_path_input = '/home/nzilberstein/repository/constrained_sampling/_exp/input/FFHQ'\n",
    "coeff = 0.0\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "dino = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
    "dino = dino.eval()\n",
    "# Calculate diversity\n",
    "cnt = 0\n",
    "mean_psnr = 0\n",
    "mean_lpips = 0\n",
    "for item in os.listdir(img_path_input):\n",
    "    if item.split('.')[0] < max_img_id:\n",
    "        # Check if the item is a directory (folder)\n",
    "        img_psld_torch_list = []    \n",
    "        for img_id in os.listdir(os.path.join(img_path, item.split('.')[0])):\n",
    "            # if img_id.split('_')[2] == \"grid.png\":\n",
    "            #     continue\n",
    "            img_id_path = os.path.join(img_path, item.split('.')[0], img_id)\n",
    "            img = Image.open(img_id_path).convert('RGB')\n",
    "\n",
    "            img_psld_torch = transforms.ToTensor()(img)\n",
    "            img_psld_torch_list.append(img_psld_torch)\n",
    "                # Transform to tensor the list\n",
    "        img_psld_torch_list = torch.stack(img_psld_torch_list)\n",
    "        # print(img_psld_torch_list.shape)\n",
    "        # Compute similarity\n",
    "        total_pair_wise_sim = 0.\n",
    "        xo_list = dino(img_psld_torch_list)\n",
    "        # del dino\n",
    "        xo_list /= xo_list.norm(dim=-1, keepdim=True)\n",
    "        # calculate the cosine similarity\n",
    "        sim = (xo_list @ xo_list.T)\n",
    "        # set the diagonal to be 0\n",
    "        sim = sim - torch.diag(sim.diag())\n",
    "        total_pair_wise_sim += sim.sum() / (sim.shape[0] * (sim.shape[0] - 1))\n",
    "        torch.clear_autocast_cache()\n",
    "        # print(total_pair_wise_sim)\n",
    "                            \n",
    "print(total_pair_wise_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37a7127a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014800000000000035"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - 0.9852"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d5b6d6",
   "metadata": {},
   "source": [
    "## REDDIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "565d217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00024.png\n",
      "00009.png\n",
      "00043.png\n",
      "00033.png\n",
      "00001.png\n",
      "00005.png\n",
      "00038.png\n",
      "00006.png\n",
      "00056.png\n",
      "00049.png\n",
      "00018.png\n",
      "00058.png\n",
      "00010.png\n",
      "00041.png\n",
      "00045.png\n",
      "00053.png\n",
      "00055.png\n",
      "00019.png\n",
      "00015.png\n",
      "00060.png\n",
      "00023.png\n",
      "00031.png\n",
      "00017.png\n",
      "00037.png\n",
      "00003.png\n",
      "00025.png\n",
      "00044.png\n",
      "00034.png\n",
      "00048.png\n",
      "00011.png\n",
      "00052.png\n",
      "00012.png\n",
      "00040.png\n",
      "00016.png\n",
      "00007.png\n",
      "00046.png\n",
      "00026.png\n",
      "00042.png\n",
      "00054.png\n",
      "00021.png\n",
      "00028.png\n",
      "00061.png\n",
      "00032.png\n",
      "00059.png\n",
      "00039.png\n",
      "00004.png\n",
      "00022.png\n",
      "00051.png\n",
      "00013.png\n",
      "00020.png\n",
      "00057.png\n",
      "00050.png\n",
      "00035.png\n",
      "00002.png\n",
      "00047.png\n",
      "00000.png\n",
      "00014.png\n",
      "00008.png\n",
      "00027.png\n",
      "00029.png\n",
      "00036.png\n",
      "00030.png\n",
      "tensor(24.3240)\n",
      "tensor([[[[0.1154]]]], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# algo = 'dps'\n",
    "# algo = 'rsd_stable'\n",
    "gamma = 80\n",
    "algo = f'rsd_stable_repulsion_gamma{gamma}'\n",
    "max_img_id = '00062'\n",
    "\n",
    "# img_path = f'/home/nzilberstein/repository/constrai/ned_sampling/_exp/output/{algo}'\n",
    "img_path = f'/home/nzilberstein/repository/constrained_sampling/_exp/output/{algo}/inp_large_box'\n",
    "img_path_input = '/home/nzilberstein/repository/constrained_sampling/_exp/input/FFHQ'\n",
    "coeff = 0.0\n",
    "import os\n",
    "import lpips\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "if algo == 'rsd_stable' or algo == f'rsd_stable_repulsion_gamma{gamma}':\n",
    "    # Calculate FID score\n",
    "    cnt = 0\n",
    "    mean_psnr = 0\n",
    "    mean_lpips = 0\n",
    "    for item in os.listdir(img_path_input):\n",
    "        if item.split('.')[0] < max_img_id:\n",
    "            print(item)\n",
    "            # Check if the item is a directory (folder)\n",
    "            img_true_path = os.path.join(img_path_input, item)\n",
    "            # print(item)\n",
    "            img_true = Image.open(img_true_path).convert('RGB')\n",
    "            img_true_torch = transforms.ToTensor()(img_true)\n",
    "            img_true_torch = upsample(img_true_torch.unsqueeze(0)).squeeze()\n",
    "            for img_id in os.listdir(os.path.join(img_path, item.split('.')[0])):\n",
    "                # if img_id.split('_')[2] == \"grid.png\":\n",
    "                #     continue\n",
    "                img_id_path = os.path.join(img_path, item.split('.')[0], img_id)\n",
    "                img = Image.open(img_id_path).convert('RGB')\n",
    "\n",
    "                img_psld_torch = transforms.ToTensor()(img)\n",
    "                # print(img_psld_torch.shape)\n",
    "                # img_psld_torch= nn.functional.interpolate(img_psld_torch.unsqueeze(0), size=(256, 256)).squeeze()\n",
    "\n",
    "                mse = torch.mean((img_psld_torch - img_true_torch) ** 2, dim=(0, 1, 2))\n",
    "                psnr = 10 * torch.log10(1 / (mse + 1e-10))\n",
    "                # print(psnr)\n",
    "                mean_psnr = mean_psnr + psnr\n",
    "\n",
    "                lpips_val = lpips_(img_psld_torch.cuda(), img_true_torch.cuda())\n",
    "                # print(lpips_val)\n",
    "                mean_lpips = mean_lpips + lpips_val\n",
    "\n",
    "                cnt = cnt + 1\n",
    "else:\n",
    "    # Calculate FID score\n",
    "    cnt = 0\n",
    "    mean_psnr = 0\n",
    "    mean_lpips = 0\n",
    "    for item in os.listdir(img_path_input):\n",
    "        if item.split('.')[0] < max_img_id:\n",
    "            # print(item)\n",
    "            # Check if the item is a directory (folder)\n",
    "            img_true_path = os.path.join(img_path_input, item)\n",
    "            # print(item)\n",
    "            img_true = Image.open(img_true_path).convert('RGB')\n",
    "            img_true_torch = transforms.ToTensor()(img_true)\n",
    "            # img_true_torch = upsample(img_true_torch.unsqueeze(0)).squeeze()\n",
    "            for img_id in os.listdir(os.path.join(img_path, item.split('.')[0])):\n",
    "                if len(img_id.split('.')[0].split('_')) == 2:\n",
    "                    print(img_id)\n",
    "                    img_id_path = os.path.join(img_path, item.split('.')[0], img_id)\n",
    "                    img = Image.open(img_id_path).convert('RGB')\n",
    "\n",
    "                    img_psld_torch = transforms.ToTensor()(img)\n",
    "\n",
    "                    mse = torch.mean((img_psld_torch - img_true_torch) ** 2, dim=(0, 1, 2))\n",
    "                    psnr = 10 * torch.log10(1 / (mse + 1e-10))\n",
    "                    # print(psnr)\n",
    "                    mean_psnr = mean_psnr + psnr\n",
    "\n",
    "                    lpips_val = lpips_(img_psld_torch.cuda(), img_true_torch.cuda())\n",
    "                    # print(lpips_val)\n",
    "                    mean_lpips = mean_lpips + lpips_val\n",
    "\n",
    "                cnt = cnt + 1\n",
    "\n",
    "\n",
    "print(mean_psnr/cnt)\n",
    "print(mean_lpips/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/home/nzilberstein/Inverse/_exp/output_bip_small_nonaugm/RED_diff_nonaug'\n",
    "it = 0\n",
    "for item in os.listdir(img_path_input):\n",
    "    # Check if the item is a directory (folder)\n",
    "    if item.isnumeric():\n",
    "        print(item)\n",
    "        list_imgs = os.listdir(os.path.join(img_path_input, item))\n",
    "        idx_img = np.random.choice(len(os.listdir(os.path.join(img_path_input, item))))\n",
    "        img_true = Image.open(os.path.join(args.dir_path, item, list_imgs[idx_img])).convert('RGB')\n",
    "\n",
    "        img_torch = transforms.ToTensor()(img_true)\n",
    "\n",
    "        # Create folder if does not exist\n",
    "        if not os.path.exists(dest_folder):\n",
    "            os.makedirs(dest_folder)\n",
    "\n",
    "        save_image(img_torch, f'{dest_folder}/{it}.png')\n",
    "    it = it + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/nicolas/red_diff_stable/PSLD/stable-diffusion/outputs/psld-samples-bip/samples/00002.png\n",
    "from PIL import Image\n",
    "import lpips\n",
    "# img_path = '/home/nzilberstein/Inverse/_exp/output_rip/PSLD/samples/00003/00000.png'\n",
    "img_id_single = '00010'\n",
    "img_path = f'/home/nzilberstein/Inverse/PSLD/stable-diffusion/outputs/psld-samples-bip/samples/{img_id_single}/00000.png'\n",
    "# img_path = f'/home/nzilberstein/Inverse/_exp/output_rip/PSLD/samples_500_iter/{img_id_single}/00000.png'\n",
    "img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "img_path_reddif = f'/home/nzilberstein/Inverse/_exp/output_rip/RED_diff/10.0/x_hat_1.png'\n",
    "# img_path_reddif = f'/home/nzilberstein/Inverse/_exp/output_rip/RED_diff/{img_id_single}/0.0/x_hat_1.png'\n",
    "img_reddif = Image.open(img_path_reddif).convert('RGB')\n",
    "\n",
    "img_true_path = f'/home/nzilberstein/Inverse/_exp/input/FFHQ/{img_id_single}.png'\n",
    "# img_true_path = '/home/nzilberstein/PSLD/diffusion-posterior-sampling/data/samples/00003.png'\n",
    "img_true = Image.open(img_true_path).convert('RGB')\n",
    "\n",
    "img_deg = Image.open('/home/nzilberstein/Inverse/_exp/output_inv/x_deg.png').convert('RGB')\n",
    "# Define upsample operation\n",
    "upsample = nn.Upsample(scale_factor=2, mode='nearest') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd1163b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d076df7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/nzilberstein/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8567, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# algo = 'reddiff'\n",
    "\n",
    "# img_path = f'/home/nzilberstein/repository/constrained_sampling/_exp/output/{algo}'\n",
    "img_path = '/home/nzilberstein/threestudio/outputs/dreamfusion-if/A_stuffed_animal_that_is_frowning_is_on_a_skateboard@20240620-014941/gamma200_false_seed1_lr001_guidance100/save/it3512-test'\n",
    "coeff = 0.0\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "dino = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
    "dino = dino.eval()\n",
    "# Calculate diversity\n",
    "cnt = 0\n",
    "mean_psnr = 0\n",
    "mean_lpips = 0\n",
    "img_psld_torch_list = [] \n",
    "for img_id in os.listdir(img_path):\n",
    "        # Check if the item is a directory (folder)\n",
    "       \n",
    "    img_id_path = os.path.join(img_path, img_id)\n",
    "    img = Image.open(img_id_path).convert('RGB')\n",
    "\n",
    "    img_psld_torch = transforms.ToTensor()(img)\n",
    "    \n",
    "    img_psld_torch_list.append(img_psld_torch[:, :, :512])\n",
    "                # Transform to tensor the list\n",
    "img_psld_torch_list = torch.stack(img_psld_torch_list, dim = 0)\n",
    "# print(img_psld_torch_list.shape)\n",
    "# Compute similarity\n",
    "total_pair_wise_sim = 0.\n",
    "xo_list = dino(img_psld_torch_list)\n",
    "# del dino\n",
    "xo_list /= xo_list.norm(dim=-1, keepdim=True)\n",
    "# calculate the cosine similarity\n",
    "sim = (xo_list @ xo_list.T)\n",
    "# set the diagonal to be 0\n",
    "sim = sim - torch.diag(sim.diag())\n",
    "total_pair_wise_sim += sim.sum() / (sim.shape[0] * (sim.shape[0] - 1))\n",
    "torch.clear_autocast_cache()\n",
    "        # print(total_pair_wise_sim)\n",
    "                            \n",
    "print(total_pair_wise_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1d903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
