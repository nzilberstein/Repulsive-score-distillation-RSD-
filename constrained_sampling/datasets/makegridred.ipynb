{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_2.png\n",
      "image_1.png\n",
      "image_3.png\n",
      "image_0.png\n",
      "image_2.png\n",
      "image_1.png\n",
      "image_3.png\n",
      "image_0.png\n",
      "/home/nzilberstein/red_diff_stable/prolific_dreamer2d/generated_images/paper/12.pdf\n"
     ]
    }
   ],
   "source": [
    "# /home/nicolas/red_diff_stable/PSLD/stable-diffusion/outputs/psld-samples-bip/samples/00002.png\n",
    "from PIL import Image\n",
    "import lpips\n",
    "import os\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt\n",
    "# img_path = '/home/nzilberstein/Inverse/_exp/output_rip/PSLD/samples/00003/00000.png'\n",
    "img_id = '12'\n",
    "img_sample = '0'\n",
    "\n",
    "# img_cfg1 = f'/home/nzilberstein/red_diff_stable/prolific_dreamer2d/generated_images/1e-10/{img_id}'\n",
    "# img_cfg4 = f'/home/nzilberstein/red_diff_stable/prolific_dreamer2d/generated_images/0.0/{img_id}'\n",
    "# img_cfg75 = f'/home/nzilberstein/red_diff_stable/prolific_dreamer2d/generated_images/0.0_CFG75/{img_id}'\n",
    "img_cfg75_10 = f'/home/nzilberstein/red_diff_stable/prolific_dreamer2d/generated_images/lpips_space/10.0/{img_id}'\n",
    "img_cfg75_10_dino = f'/home/nzilberstein/red_diff_stable/prolific_dreamer2d/generated_images/10.0/{img_id}'\n",
    "# img_cfg75_20 = f'/home/nzilberstein/red_diff_stable/prolific_dreamer2d/generated_images/20.0/1000iter/{img_id}'\n",
    "# img_cfg75_30 = f'/home/nzilberstein/red_diff_stable/prolific_dreamer2d/generated_images/30.0/{img_id}'\n",
    "# img_cfg75_40 = f'/home/nzilberstein/red_diff_stable/prolific_dreamer2d/generated_images/40.0/1000iter/{img_id}'\n",
    "\n",
    "list_img_paths = [img_cfg75_10, img_cfg75_10_dino]\n",
    "\n",
    "it = 0\n",
    "list_grid = []\n",
    "for img_path_idx in list_img_paths:\n",
    "    list_img = []\n",
    "    for item in os.listdir(img_path_idx):\n",
    "        print(item)\n",
    "        aux = os.path.join(img_path_idx, item)\n",
    "    # # img_path = f'/home/nzilberstein/Inverse/_exp/output_rip/PSLD/samples_500_iter/{img_id_single}/00000.png'\n",
    "        img = Image.open(aux).convert('RGB')\n",
    "        list_img.append(transforms.ToTensor()(img))\n",
    "\n",
    "    # Make grid with all the images in list_img\n",
    "    grid = make_grid(list_img, nrow=4)\n",
    "    list_grid.append(grid)\n",
    "    \n",
    "grid = make_grid(list_grid, nrow=1)\n",
    "    # append grid at each loop \n",
    "print(os.path.join('/home/nzilberstein/red_diff_stable/prolific_dreamer2d/generated_images/paper/', f'{img_id}.pdf'))\n",
    "save_image(grid, os.path.join('/home/nzilberstein/red_diff_stable/prolific_dreamer2d/generated_images/paper/', f'{img_id}_lpips.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/nicolas/red_diff_stable/PSLD/stable-diffusion/outputs/psld-samples-bip/samples/00002.png\n",
    "from PIL import Image\n",
    "import lpips\n",
    "import os\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "list_img = []\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "    transforms.ToTensor()\n",
    "]) \n",
    "img_id = \"00001\"\n",
    "# list_img_orig = []\n",
    "# img = Image.open(f'/home/nzilberstein/Inverse/_exp/input/FFHQ/{img_id}.png').convert('RGB')\n",
    "# upsample = nn.Upsample(scale_factor=2, mode='nearest') \n",
    "# img_true_torch = transform(img)\n",
    "# img_true_torch = upsample(img_true_torch.unsqueeze(0)).squeeze()\n",
    "# list_img_orig.append(img_true_torch)\n",
    "\n",
    "\n",
    "# img = Image.open(f'/home/nzilberstein/Inverse/_exp/output_inv/x_deg_{img_id}.png').convert('RGB')\n",
    "# list_img_orig.append(transform(img))\n",
    "\n",
    "# grid_input = make_grid(list_img_orig, nrow=2)\n",
    "# save_image(grid_input, os.path.join('/home/nzilberstein/Inverse/_exp', f'sr8_{img_id}_input_deg.pdf'))\n",
    "\n",
    "\n",
    "img_path_idx = f\"/home/nzilberstein/Inverse/_exp/output_deblur_gaus/PSLD/samples/samples/{img_id}\"\n",
    "list_img = []\n",
    "for item in os.listdir(img_path_idx):\n",
    "    # if len(item.split('_')) > 1:\n",
    "    #     continue\n",
    "    if item.split('_')[0] != 'temp':\n",
    "        continue\n",
    "    aux = os.path.join(img_path_idx, item)\n",
    "# # img_path = f'/home/nzilberstein/Inverse/_exp/output_rip/PSLD/samples_500_iter/{img_id_single}/00000.png'\n",
    "    img = Image.open(aux).convert('RGB')\n",
    "    list_img.append(transforms.ToTensor()(img))\n",
    "\n",
    "# Make grid with all the images in list_img\n",
    "grid_PSDL = make_grid(list_img, nrow=4)\n",
    "list_img = [grid_PSDL]\n",
    "\n",
    "img = Image.open(f'/home/nzilberstein/Inverse/_exp/output_deblur_gauss/RED_diff/{img_id}/0.0/x_hat_grid.png').convert('RGB')\n",
    "list_img.append(transform(img))\n",
    "\n",
    "# img = Image.open(f'/home/nzilberstein/Inverse/_exp/output_bip_large/RED_diff_nonaug/{img_id}/0.0/x_hat_grid.png').convert('RGB')\n",
    "# list_img.append(transform(img))\n",
    "\n",
    "grid = make_grid(list_img, nrow=1)\n",
    "save_image(grid, os.path.join('/home/nzilberstein/Inverse/_exp', f'sr8_{img_id}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/nicolas/red_diff_stable/PSLD/stable-diffusion/outputs/psld-samples-bip/samples/00002.png\n",
    "from PIL import Image\n",
    "import lpips\n",
    "import os\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "list_img = []\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((512, 512))\n",
    "]) \n",
    "\n",
    "list_img_orig = []\n",
    "img_id = '00027'\n",
    "img = Image.open(f'/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/_exp/input/FFHQ_512/{img_id}.png').convert('RGB')\n",
    "# img = Image.open(f'/home/nzilberstein/repository/constrained_sampling/_exp/input/imagenet/n01537544_indigo_bunting.JPEG').convert('RGB')\n",
    "img_true_torch = transform(img)\n",
    "list_img_orig.append(img_true_torch)\n",
    "\n",
    "img = Image.open(f'/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/degs/{img_id}_{deg}.png').convert('RGB')\n",
    "list_img_orig.append(transform(img))\n",
    "\n",
    "grid_input = make_grid(list_img_orig, nrow=2)\n",
    "save_image(grid_input, os.path.join('/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/output', f'{img_id}_inp_random_deg.pdf'))\n",
    "\n",
    "\n",
    "# img_path_idx = f\"/home/nzilberstein/Inverse/_exp/output_bip_large/PSLD/samples/{img_id}\"\n",
    "# list_img = []\n",
    "# # for item in os.listdir(img_path_idx):\n",
    "# #     if len(item.split('_')) > 1:\n",
    "# #         continue\n",
    "# #     aux = os.path.join(img_path_idx, item)\n",
    "# # # # img_path = f'/home/nzilberstein/Inverse/_exp/output_rip/PSLD/samples_500_iter/{img_id_single}/00000.png'\n",
    "# #     img = Image.open(aux).convert('RGB')\n",
    "# #     list_img.append(transforms.ToTensor()(img))\n",
    "\n",
    "# # # Make grid with all the images in list_img\n",
    "# # grid_PSDL = make_grid(list_img, nrow=4)\n",
    "# # list_img = [grid_PSDL]\n",
    "\n",
    "# transform = transforms.Compose([ \n",
    "#     transforms.ToTensor()\n",
    "# ]) \n",
    "# img = Image.open(f'/home/nzilberstein/Inverse/_exp/output_rip/RED_diff/0.0/0.05/x_hat_grid.png').convert('RGB')\n",
    "# list_img.append(transform(img))\n",
    "\n",
    "# # img = Image.open(f'/home/nzilberstein/Inverse/_exp/output_rip/RED_diff_nonaug/{img_id}/0.0/x_hat_grid.png').convert('RGB')\n",
    "# # list_img.append(transform(img))\n",
    "\n",
    "# grid = make_grid(list_img, nrow=1)\n",
    "# save_image(grid, os.path.join('/home/nzilberstein/Inverse/_exp', f'bip_large_imagenet_1.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/nicolas/red_diff_stable/PSLD/stable-diffusion/outputs/psld-samples-bip/samples/00002.png\n",
    "from PIL import Image\n",
    "import lpips\n",
    "import os\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "list_img = []\n",
    "\n",
    "upsample = nn.Upsample(scale_factor=2, mode='nearest') \n",
    "transform = transforms.Compose([ \n",
    "    transforms.ToTensor()\n",
    "]) \n",
    "algo = 'rlsd'\n",
    "# algo_repul = 'rsd_stable_repulsion_gamma50'\n",
    "img_id = \"00027\"\n",
    "deg = 'inp_random'\n",
    "\n",
    "# img_path_red = f'/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/_exp/output/{algo}'\n",
    "# img_path_idx = f\"/home/nicolas/server_nvidia/PSLD/stable-diffusion/outputs/psld-ldm-samples-sr/samples/{img_id}\"\n",
    "img_path_red = f'/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/{algo}/{deg}'\n",
    "img_path_red_repul = f'/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/reddiff/{deg}'\n",
    "img_path_idx = f\"/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/psld/{deg}/{img_id}\"\n",
    "\n",
    "list_img = []\n",
    "list_img_grids = []\n",
    "for item in os.listdir(img_path_idx):\n",
    "    # if len(item.split('_')) > 1:\n",
    "    #     continue\n",
    "    # if item.split('_')[0] != 'temp':\n",
    "    #     continue\n",
    "    aux = os.path.join(img_path_idx, item)\n",
    "    img = Image.open(aux).convert('RGB')\n",
    "    list_img.append(transforms.ToTensor()(img))\n",
    "\n",
    "# Make grid with all the images in list_img\n",
    "grid_PSDL = make_grid(list_img, nrow=4)\n",
    "list_img_grids = [grid_PSDL]\n",
    "\n",
    "# list_img = []\n",
    "# img_path_idx = f\"{img_path_red_repul}/{img_id}\"\n",
    "# for item in os.listdir(img_path_idx):\n",
    "#     # if len(item.split('_'))[] 1:\n",
    "#     #     continue\n",
    "#     # if item.split('_')[0] != 'temp':\n",
    "#     #     continue\n",
    "#     aux = os.path.join(img_path_idx, item)\n",
    "#     img = Image.open(aux).convert('RGB')\n",
    "#     img_true_torch = transforms.ToTensor()(img)\n",
    "#     img = upsample(img_true_torch.unsqueeze(0)).squeeze()\n",
    "#     list_img.append(img)\n",
    "\n",
    "# list_img_orig.extend(list_img[0:1])\n",
    "\n",
    "### OURS\n",
    "\n",
    "list_img = []\n",
    "img_path_idx = f\"{img_path_red}/{img_id}\"\n",
    "for item in os.listdir(img_path_idx):\n",
    "    # if item.split('_')[2] == \"grid.png\":\n",
    "    #     continue\n",
    "    # if item.split('_')[0] != 'temp':\n",
    "    #     continue\n",
    "    aux = os.path.join(img_path_idx, item)\n",
    "    img = Image.open(aux).convert('RGB')\n",
    "    list_img.append(transforms.ToTensor()(img))\n",
    "\n",
    "# Make grid with all the images in list_img\n",
    "grid_RED = make_grid(list_img, nrow=4)\n",
    "list_img_grids.append(grid_RED)\n",
    "\n",
    "\n",
    "# # Make grid with all the images in list_img\n",
    "# grid_RED_repul = make_grid(list_img, nrow=4)\n",
    "# list_img_grids.append(grid_RED_repul)\n",
    "# img = Image.open(f'/home/nzilberstein/Inverse/_exp/output_bip_large/RED_diff_nonaug/{img_id}/0.0/x_hat_grid.png').convert('RGB')\n",
    "# list_img.append(transform(img))\n",
    "\n",
    "grid = make_grid(list_img_grids, nrow=1)\n",
    "# Merge two grid with grid_input above\n",
    "\n",
    "# grid = make_grid([grid_input, grid], nrow=1)\n",
    "\n",
    "\n",
    "save_image(grid, os.path.join('/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/output', f'{img_id}_{deg}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.png\n",
      "200.png\n",
      "300.png\n",
      "500.png\n",
      "999.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# /home/nicolas/red_diff_stable/PSLD/stable-diffusion/outputs/psld-samples-bip/samples/00002.png\n",
    "from PIL import Image\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.transforms as transforms \n",
    "import os \n",
    "\n",
    "list_img = []\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((512, 512))\n",
    "]) \n",
    "\n",
    "\n",
    "## GET IMAGES AND DEG\n",
    "\n",
    "list_img_orig = []\n",
    "img_id = '00005'\n",
    "deg = 'inp_free_mask'\n",
    "\n",
    "img = Image.open(f'/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/_exp/input/FFHQ_512/{img_id}.png').convert('RGB')\n",
    "# img = Image.open(f'/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/_exp/input/IMAGENET/{img_id}.png').convert('RGB')\n",
    "# img = Image.open(f'/home/nzilberstein/repository/constrained_sampling/_exp/input/imagenet/n01537544_indigo_bunting.JPEG').convert('RGB')\n",
    "img_true_torch = transform(img)\n",
    "list_img_orig.append(img_true_torch)\n",
    "\n",
    "img = Image.open(f'/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/degs/{img_id}_{deg}.png').convert('RGB')\n",
    "list_img_orig.append(transform(img))\n",
    "\n",
    "grid_input = make_grid(list_img_orig, nrow=2)\n",
    "\n",
    "save_image(grid_input, os.path.join('/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/output', f'{img_id}_deg_{deg}.pdf'))\n",
    "\n",
    "## GET IMAGES FROM EXPERIMENTS\n",
    "\n",
    "list_img = []\n",
    "\n",
    "# upsample = nn.Upsample(scale_factor=2, mode='nearest') \n",
    "# transform = transforms.Compose([ \n",
    "#     transforms.ToTensor()\n",
    "# ]) \n",
    "\n",
    "algo = 'rlsd'\n",
    "# img_id = \"00036\"\n",
    "\n",
    "img_path_red = f'/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/rlsd/ablation_steps'\n",
    "# img_path_idx = f\"/home/nicolas/server_nvidia/PSLD/stable-diffusion/outputs/psld-ldm-samples-sr/samples/{img_id}\"\n",
    "# img_path_idx = f\"/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/rlsd/ablation_steps/{img_id}\"\n",
    "\n",
    "list_img = []\n",
    "list_img_grids = []\n",
    "img_path_idx = f\"{img_path_red}/{img_id}\"\n",
    "for item in ['100.png', '200.png', '300.png', '500.png', '999.png']:\n",
    "    print(item)\n",
    "    # if item.split('_')[2] == \"grid.png\":\n",
    "    #     continue\n",
    "    # if item.split('_')[0] != 'temp':\n",
    "    #     continue\n",
    "    aux = os.path.join(img_path_idx, item)\n",
    "    img = Image.open(aux).convert('RGB')\n",
    "    list_img.append(transforms.ToTensor()(img))\n",
    "\n",
    "list_img_orig.extend(list_img)\n",
    "\n",
    "grid = make_grid(list_img, nrow=5)\n",
    "# Merge two grid with grid_input above\n",
    "\n",
    "# grid = make_grid([grid_input, grid], nrow=1)\n",
    "\n",
    "\n",
    "save_image(grid, os.path.join('/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/output', f'{img_id}_{deg}.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single folder random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/nicolas/red_diff_stable/PSLD/stable-diffusion/outputs/psld-samples-bip/samples/00002.png\n",
    "from PIL import Image\n",
    "import lpips\n",
    "import os\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "list_img = []\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "    transforms.ToTensor()\n",
    "]) \n",
    "\n",
    "list_img = []\n",
    "img_path_idx = \"/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/failures\"\n",
    "for item in os.listdir(img_path_idx):\n",
    "    if len(item.split('_')) == 0:\n",
    "        continue\n",
    "    # if item.split('_')[0] != 'temp':\n",
    "    #     continue\n",
    "    aux = os.path.join(img_path_idx, item)\n",
    "    img = Image.open(aux).convert('RGB')\n",
    "    list_img.append(transforms.ToTensor()(img))\n",
    "\n",
    "# Make grid with all the images in list_img\n",
    "grid_RED = make_grid(list_img, nrow=3)\n",
    "\n",
    "save_image(grid_RED, os.path.join('/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/failures', f'failures_imagenet.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/nicolas/red_diff_stable/PSLD/stable-diffusion/outputs/psld-samples-bip/samples/00002.png\n",
    "from PIL import Image\n",
    "import lpips\n",
    "import os\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.transforms as transforms \n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "list_img = []\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "    transforms.ToTensor()\n",
    "]) \n",
    "\n",
    "list_img = []\n",
    "img_path_idx = \"/home/nicolas/Repulsive-score-distillation-RSD-/drive-download-20240910T231938Z-001\"\n",
    "for item in os.listdir(img_path_idx):\n",
    "    if len(item.split('_')) == 0:\n",
    "        continue\n",
    "    # if item.split('_')[0] != 'temp':\n",
    "    #     continue\n",
    "    aux = os.path.join(img_path_idx, item)\n",
    "    img = Image.open(aux).convert('RGB')\n",
    "    list_img.append(transforms.ToTensor()(img))\n",
    "\n",
    "# Make grid with all the images in list_img\n",
    "grid_RED = make_grid(list_img, nrow=4)\n",
    "\n",
    "save_image(grid_RED, os.path.join('/home/nicolas/Repulsive-score-distillation-RSD-/drive-download-20240910T231938Z-001', f'slides.pdf'))\n",
    "\n",
    "# Set the patch coordinates and size (top-left corner and width, height)\n",
    "patch_coords = (128, 128)  # (y, x) starting point of the patch\n",
    "patch_size = (100, 100)    # height and width of the patch\n",
    "\n",
    "for item in os.listdir(img_path_idx):\n",
    "    if len(item.split('_')) == 0:\n",
    "        continue\n",
    "\n",
    "\n",
    "        # if item.split('_')[0] != 'temp':\n",
    "    #     continue\n",
    "    aux = os.path.join(img_path_idx, item)\n",
    "    img = Image.open(aux).convert('RGB')\n",
    "    image_tensor = transforms.ToTensor()(img)\n",
    "\n",
    "    # Extract the patch\n",
    "    y, x = patch_coords\n",
    "    h, w = patch_size\n",
    "    patch = image_tensor[:, y:y+h, x:x+w]\n",
    "\n",
    "    # Zoom in on the patch by resizing it (using bilinear interpolation)\n",
    "    zoom_factor = 4  # for example, zoom by 4x\n",
    "    zoomed_patch = nn.functional.interpolate(patch.unsqueeze(0), scale_factor=zoom_factor, mode='bilinear', align_corners=False)\n",
    "    zoomed_patch = zoomed_patch.squeeze(0)\n",
    "    list_img.append(zoomed_patch)\n",
    "\n",
    "grid_RED = make_grid(list_img, nrow=4)\n",
    "\n",
    "save_image(grid_RED, os.path.join('/home/nicolas/Repulsive-score-distillation-RSD-/drive-download-20240910T231938Z-001', f'zoom.pdf'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "output_fmt = 'pil'  # 'pil' or 'matplotlib'\n",
    "\n",
    "# Load the image\n",
    "# image_path = 'your_image.jpg'\n",
    "image = img\n",
    "transform = transforms.ToTensor()\n",
    "image_tensor = transform(image)\n",
    "\n",
    "# Set the patch coordinates and size (top-left corner and width, height)\n",
    "patch_coords = (128, 128)  # (y, x) starting point of the patch\n",
    "patch_size = (100, 100)    # height and width of the patch\n",
    "\n",
    "# Extract the patch\n",
    "y, x = patch_coords\n",
    "h, w = patch_size\n",
    "patch = image_tensor[:, y:y+h, x:x+w]\n",
    "\n",
    "# Zoom in on the patch by resizing it (using bilinear interpolation)\n",
    "zoom_factor = 4  # for example, zoom by 4x\n",
    "zoomed_patch = torch.nn.functional.interpolate(patch.unsqueeze(0), scale_factor=zoom_factor, mode='bilinear', align_corners=False)\n",
    "zoomed_patch = zoomed_patch.squeeze(0)\n",
    "\n",
    "# Convert back to PIL for saving and displaying\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "# Original image in PIL format\n",
    "original_image = to_pil(image_tensor)\n",
    "\n",
    "# Zoomed patch as PIL image\n",
    "zoomed_patch_pil = to_pil(zoomed_patch)\n",
    "\n",
    "if output_fmt == 'matplotlib':\n",
    "\n",
    "    # Plot the result\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Show the original image\n",
    "    ax.imshow(original_image)\n",
    "\n",
    "    # Add the zoomed patch as an inset (you can adjust position and size)\n",
    "    inset_ax = fig.add_axes([0.6, 0.6, 0.25, 0.25])  # [left, bottom, width, height] (relative to figure size)\n",
    "    inset_ax.imshow(zoomed_patch_pil)\n",
    "    inset_ax.set_xticks([])\n",
    "    inset_ax.set_yticks([])\n",
    "\n",
    "    # Save the figure\n",
    "    output_path = '/home/nicolas/Repulsive-score-distillation-RSD-/drive-download-20240910T231938Z-001/image_with_zoomed_patch.png'\n",
    "    plt.savefig(output_path)\n",
    "\n",
    "    print(f\"Saved image with zoomed patch overlayed at: {output_path}\")\n",
    "\n",
    "elif output_fmt == 'pil':\n",
    "\n",
    "    # Paste the zoomed patch onto the original image\n",
    "    image_copy = image.copy()\n",
    "\n",
    "    # Calculate the position where the zoomed patch will be placed\n",
    "    patch_position = (0, 400)  # Adjust this to place the patch wherever you want on the original image\n",
    "    image_copy.paste(zoomed_patch_pil, patch_position)\n",
    "\n",
    "    # # Save or display the resulting image\n",
    "    output_path = '/home/nicolas/Repulsive-score-distillation-RSD-/drive-download-20240910T231938Z-001/image_with_zoomed_patch.png'\n",
    "    image_copy.save(output_path)\n",
    "\n",
    "    # # Display the image (optional)\n",
    "    # image_copy.show()\n",
    "\n",
    "    # print(f\"Image with zoomed patch saved at: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAPER - APPENDIX - LARGE GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/nicolas/red_diff_stable/PSLD/stable-diffusion/outputs/psld-samples-bip/samples/00002.png\n",
    "from PIL import Image\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torchvision.transforms as transforms \n",
    "import os \n",
    "\n",
    "list_img = []\n",
    "\n",
    "transform = transforms.Compose([ \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((512, 512))\n",
    "]) \n",
    "\n",
    "\n",
    "## GET IMAGES AND DEG\n",
    "\n",
    "list_img_orig = []\n",
    "img_id = '00011'\n",
    "deg = 'hdr'\n",
    "\n",
    "img = Image.open(f'/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/_exp/input/FFHQ_512/{img_id}.png').convert('RGB')\n",
    "# img = Image.open(f'/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/_exp/input/IMAGENET/{img_id}.png').convert('RGB')\n",
    "# img = Image.open(f'/home/nzilberstein/repository/constrained_sampling/_exp/input/imagenet/n01537544_indigo_bunting.JPEG').convert('RGB')\n",
    "img_true_torch = transform(img)\n",
    "list_img_orig.append(img_true_torch)\n",
    "\n",
    "img = Image.open(f'/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/degs/{img_id}_{deg}.png').convert('RGB')\n",
    "list_img_orig.append(transform(img))\n",
    "\n",
    "grid_input = make_grid(list_img_orig, nrow=2)\n",
    "\n",
    "## GET IMAGES FROM EXPERIMENTS\n",
    "\n",
    "list_img = []\n",
    "\n",
    "# upsample = nn.Upsample(scale_factor=2, mode='nearest') \n",
    "# transform = transforms.Compose([ \n",
    "#     transforms.ToTensor()\n",
    "# ]) \n",
    "\n",
    "algo = 'rlsd'\n",
    "# img_id = \"00036\"\n",
    "\n",
    "# img_path_red = f'/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/_exp/output/{algo}'\n",
    "# img_path_idx = f\"/home/nicolas/server_nvidia/PSLD/stable-diffusion/outputs/psld-ldm-samples-sr/samples/{img_id}\"\n",
    "img_path_red = f'/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/{algo}/{deg}'\n",
    "img_path_red_repul = f'/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/reddiff/{deg}'\n",
    "img_path_idx = f\"/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/psld/{deg}/{img_id}\"\n",
    "\n",
    "# list_img = []\n",
    "# list_img_grids = []\n",
    "# for item in os.listdir(img_path_idx):\n",
    "#     # if len(item.split('_')) > 1:\n",
    "#     #     continue\n",
    "#     # if item.split('_')[0] != 'temp':\n",
    "#     #     continue\n",
    "#     aux = os.path.join(img_path_idx, item)\n",
    "#     img = Image.open(aux).convert('RGB')\n",
    "#     # list_img.append(transforms.ToTensor()(img))\n",
    "#     img_true_torch = transforms.ToTensor()(img)\n",
    "#     # img = upsample(img_true_torch.unsqueeze(0)).squeeze()\n",
    "#     img = img_true_torch\n",
    "#     list_img.append(img)\n",
    "\n",
    "# list_img_orig.extend(list_img[0:1])\n",
    "# Make grid with all the images in list_img\n",
    "# grid_PSDL = make_grid(list_img, nrow=2)\n",
    "# list_img_grids = [grid_PSDL]\n",
    "\n",
    "# list_img = []\n",
    "# img_path_idx = f\"{img_path_red_repul}/{img_id}\"\n",
    "# for item in os.listdir(img_path_idx):\n",
    "#     # if len(item.split('_'))[] 1:\n",
    "#     #     continue\n",
    "#     # if item.split('_')[0] != 'temp':\n",
    "#     #     continue\n",
    "#     aux = os.path.join(img_path_idx, item)\n",
    "#     img = Image.open(aux).convert('RGB')\n",
    "#     img_true_torch = transforms.ToTensor()(img)\n",
    "#     img = upsample(img_true_torch.unsqueeze(0)).squeeze()\n",
    "#     list_img.append(img)\n",
    "\n",
    "# list_img_orig.extend(list_img[0:1])\n",
    "\n",
    "### OURS\n",
    "\n",
    "list_img = []\n",
    "img_path_idx = f\"{img_path_red}/{img_id}\"\n",
    "for item in os.listdir(img_path_idx):\n",
    "    # if item.split('_')[2] == \"grid.png\":\n",
    "    #     continue\n",
    "    # if item.split('_')[0] != 'temp':\n",
    "    #     continue\n",
    "    aux = os.path.join(img_path_idx, item)\n",
    "    img = Image.open(aux).convert('RGB')\n",
    "    list_img.append(transforms.ToTensor()(img))\n",
    "\n",
    "list_img_orig.extend(list_img[0:1])\n",
    "# Make grid with all the images in list_img\n",
    "# grid_RED = make_grid(list_img, nrow=2)\n",
    "# list_img_grids.append(grid_RED)\n",
    "\n",
    "\n",
    "# # Make grid with all the images in list_img\n",
    "# grid_RED_repul = make_grid(list_img, nrow=4)\n",
    "# list_img_grids.append(grid_RED_repul)\n",
    "# img = Image.open(f'/home/nzilberstein/Inverse/_exp/output_bip_large/RED_diff_nonaug/{img_id}/0.0/x_hat_grid.png').convert('RGB')\n",
    "# list_img.append(transform(img))\n",
    "\n",
    "grid = make_grid(list_img_orig, nrow=6)\n",
    "# Merge two grid with grid_input above\n",
    "\n",
    "# grid = make_grid([grid_input, grid], nrow=1)\n",
    "\n",
    "\n",
    "save_image(grid, os.path.join('/home/nicolas/Repulsive-score-distillation-RSD-/constrained_sampling/datasets/images_appendix/output', f'{img_id}_{deg}.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
